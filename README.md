# NLPlay with Transformers
Progress report of 'NLPlay with Transformers'
<hr>

## Week-1
- introduction to ***google colab***
- learned basic ***python programming***
- learned libraries for ***ML : numpy, pandas, matplotlib***
<hr>

## Week-2
- learned to use ***nltk*** library for NLP and DL
- learned theory behind ***neural networking***
- learned to use ***pyTorch library*** for making classifiers
<hr>

## Week-3
- made a numerical classifier using MNIST dataset for practice
- saw numerous advancements in ***deep NLP*** in detail
- further explored the applications of deep NLP
- learned to use various types of ***word embeddings***
- made a ***sentiment classifier*** using Feed Forwarded NN <br> 
  for this IMDB movie review dataset was used <br>
  for this task simple BOW(bag-of-words) representation was used
  reached accuracy of **80.02%**
  <hr>

## Post mid-sem week (Week-4)
- learned how a recurrent neural network works
- made a ***sentiment classifier*** using RNN <br>
  for this the same IMDB movie review dataset was used <br>
  reached accuracy of **87.28%**
- learned the LSTM and GRU models
- implemented these in the sentiment classifier <br>
  reached accuracy of **86.51%** and **89.86%**
  <hr>
  
## Week-5
- learned what a transformer is and how it works
<hr>

## Week-6
- made ***sentiment classifiers*** using BERT
- reached accuracy of **90.36%**
<hr>

## Week-7
- made ***sentiment classifiers*** using RoBERTa
- reached accuracy of **91.02%**
<hr>

## Week-8
- saw what **GPT-2** and **T5** are
- learned how to generate text using **transformers**
- created a custom dataset
- generated text using GPT-2 
- analysed output by calculating the **BLEU Score**
<hr>
