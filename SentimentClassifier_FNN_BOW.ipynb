{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentClassifier_FNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgQEmy22AOSB",
        "outputId": "1f2d5186-7ffe-4c65-89ea-7bc8aa45c9ef"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F  \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "transforms = torchvision.transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "nltk.download(['punkt','wordnet','stopwords'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7HVhyRCuNd"
      },
      "source": [
        "# Device configuration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXz06yQCCy7k"
      },
      "source": [
        "# downloading dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IMDB Dataset.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "VEp7IY3GESmM",
        "outputId": "e90d98b1-0abe-4334-989a-1deac11054e9"
      },
      "source": [
        "print(df.columns)\n",
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['review', 'sentiment'], dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>49582</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   review sentiment\n",
              "count                                               50000     50000\n",
              "unique                                              49582         2\n",
              "top     Loved today's show!!! It was a variety and not...  positive\n",
              "freq                                                    5     25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYk0toYiUzmT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4BkVfOTH4V",
        "outputId": "6e4e2d67-1492-4917-a615-ac6736ac8b2f"
      },
      "source": [
        "# binary sentiments\n",
        "df['sentiment'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s21oz6IpUwDJ"
      },
      "source": [
        "## **TEXT PROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p44LYfXaUS9P"
      },
      "source": [
        "#### Removing Stopwords and Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2W-ubQiI_sn"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "df['reduced_text'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "# stopwords eliminated"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww6vsLtULMF8"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    final = \"\".join(p for p in text if p not in (\"?\", \".\", \";\", \":\", \"!\", '\"', ','))\n",
        "    return final\n",
        "\n",
        "df['reduced_text'] = df['reduced_text'].apply(remove_punctuation)\n",
        "\n",
        "# punctuations removed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go58ByBHVQFa"
      },
      "source": [
        "#### Removing html tags and lowering case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZjJj_x9cMuB"
      },
      "source": [
        "def tag_removal(text):\n",
        "    sum = ''\n",
        "    include = True\n",
        "    for char in text:\n",
        "        if char == '<':\n",
        "            include = False\n",
        "        if (include): sum = sum+char\n",
        "        if char == '>':\n",
        "            include = True\n",
        "            sum = sum + ' '\n",
        "    return sum\n",
        "\n",
        "df['reduced_text'] = df['reduced_text'].apply(tag_removal)\n",
        "\n",
        "# html tags removed"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "O8mdSMlVefMq",
        "outputId": "7e41a14a-90a5-4b6c-b210-309fa38a6ab7"
      },
      "source": [
        "df['reduced_text'][0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One reviewers mentioned watching 1 Oz episode hooked They right exactly happened me  The first thing struck Oz brutality unflinching scenes violence set right word GO Trust me show faint hearted timid This show pulls punches regards drugs sex violence Its hardcore classic use word  It called OZ nickname given Oswald Maximum Security State Penitentary It focuses mainly Emerald City experimental section prison cells glass fronts face inwards privacy high agenda Em City home manyAryans Muslims gangstas Latinos Christians Italians Irish moreso scuffles death stares dodgy dealings shady agreements never far away  I would say main appeal show due fact goes shows dare Forget pretty pictures painted mainstream audiences forget charm forget romanceOZ mess around The first episode I ever saw struck nasty surreal I say I ready it I watched more I developed taste Oz got accustomed high levels graphic violence Not violence injustice (crooked guards who'll sold nickel inmates who'll kill order get away it well mannered middle class inmates turned prison bitches due lack street skills prison experience) Watching Oz may become comfortable uncomfortable viewingthats get touch darker side\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIqinMjoVrP0"
      },
      "source": [
        "text_cleaning_repo = \"@\\S+|https?:\\S+|http?:\\S+|[^A-Za-z0-9]+\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM5adfSZWEwp"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = re.sub(text_cleaning_repo,' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    tokens.append(token)\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "df[\"reduced_text\"] = df[\"reduced_text\"].apply(clean_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40s0kwgfXOlZ"
      },
      "source": [
        "#### Lemmatization and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjGPsia6XZ8w"
      },
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "  return \" \".join([lemma.lemmatize(word) for word in text.split()])\n",
        "\n",
        "df[\"reduced_text\"]  = df[\"reduced_text\"].apply(lambda text: lemmatize_text(str(text)))\n",
        "\n",
        "# lemmatization complete "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz60TFowZC7d"
      },
      "source": [
        "df[\"tokenized_text\"] = df[\"reduced_text\"].apply(lambda text: word_tokenize(text))\n",
        "\n",
        "# all documents tokenized"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "K7tTkzDdb6I5",
        "outputId": "7a81ac89-b376-4afe-94ce-e880551a17c9"
      },
      "source": [
        "df['label'] = [2*(sent=='positive')-1 for sent in df['sentiment']]\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>reduced_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
              "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>a wonderful little production the filming tech...</td>\n",
              "      <td>[a, wonderful, little, production, the, filmin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>i thought wonderful way spend time hot summer ...</td>\n",
              "      <td>[i, thought, wonderful, way, spend, time, hot,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically there s family little boy jake think...</td>\n",
              "      <td>[basically, there, s, family, little, boy, jak...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei s love time money visually stunn...</td>\n",
              "      <td>[petter, mattei, s, love, time, money, visuall...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ... label\n",
              "0  One of the other reviewers has mentioned that ...  ...     1\n",
              "1  A wonderful little production. <br /><br />The...  ...     1\n",
              "2  I thought this was a wonderful way to spend ti...  ...     1\n",
              "3  Basically there's a family where a little boy ...  ...    -1\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k104VAvMmA_k"
      },
      "source": [
        "#### Splitting the dataset into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KabV0htPmPtI"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df[['tokenized_text']], df['sentiment'],shuffle=True,test_size=0.1,random_state=10)\n",
        "\n",
        "X_train = X_train.reset_index()\n",
        "X_test = X_test.reset_index()\n",
        "Y_train = Y_train.to_frame()\n",
        "Y_train = Y_train.reset_index()\n",
        "Y_test = Y_test.to_frame()\n",
        "Y_test = Y_test.reset_index()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Sa6pIQnYzP"
      },
      "source": [
        "# **FEED FORWARDED MODEL**\n",
        "Creating a NN model with 3 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "-8o7WGixneE8",
        "outputId": "fd2ee6aa-1520-4c55-8cf0-0b7a9999d5c0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>reduced_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
              "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>a wonderful little production the filming tech...</td>\n",
              "      <td>[a, wonderful, little, production, the, filmin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>i thought wonderful way spend time hot summer ...</td>\n",
              "      <td>[i, thought, wonderful, way, spend, time, hot,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically there s family little boy jake think...</td>\n",
              "      <td>[basically, there, s, family, little, boy, jak...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei s love time money visually stunn...</td>\n",
              "      <td>[petter, mattei, s, love, time, money, visuall...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ... label\n",
              "0  One of the other reviewers has mentioned that ...  ...     1\n",
              "1  A wonderful little production. <br /><br />The...  ...     1\n",
              "2  I thought this was a wonderful way to spend ti...  ...     1\n",
              "3  Basically there's a family where a little boy ...  ...    -1\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf4ZhmDlnngJ"
      },
      "source": [
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        \n",
        "        # First Hidden Layer\n",
        "        self.f1 = nn.Linear(input_dim, hidden_dim) \n",
        "        self.relu1 = nn.ReLU()                     #this adds non-linearity\n",
        "\n",
        "        # Second Hidden Layer\n",
        "        self.f2 = nn.Linear(hidden_dim, hidden_dim) \n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Third Hidden Layer\n",
        "        self.f3 = nn.Linear(hidden_dim, hidden_dim) \n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Output Layer\n",
        "        self.f4 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.f1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.relu2(self.f2(out))\n",
        "\n",
        "        out = self.relu3(self.f3(out))\n",
        "\n",
        "        out = self.f4(out)\n",
        "\n",
        "        return F.softmax(out, dim=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqDgYVIguYu-"
      },
      "source": [
        "#### Generating input and label tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dgJSeWkqQGB"
      },
      "source": [
        "def make_dict(df):\n",
        "  review_dict = corpora.Dictionary(df[\"tokenized_text\"])\n",
        "  return review_dict\n",
        "\n",
        "review_dict = make_dict(df)\n",
        "\n",
        "# dictionary created"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nrxJQyRviBj"
      },
      "source": [
        "# hyperparameters\n",
        "\n",
        "VOCAB_SIZE = len(review_dict)\n",
        "input_dim = VOCAB_SIZE\n",
        "hidden_dim = 500\n",
        "output_dim = 2\n",
        "num_epochs = 2\n",
        "learning_rate=0.1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbvE78yevkiY"
      },
      "source": [
        "# Function to make bow vector to be used as input to network\n",
        "def make_bow_vector(review_dict, sentence):\n",
        "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
        "    for word in sentence:\n",
        "        vec[review_dict.token2id[word]] += 1\n",
        "    return vec.view(1, -1).float()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkHKs7cE6flB"
      },
      "source": [
        "# Function to get the output tensor\n",
        "def make_target(label):\n",
        "    if label == 1:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)\n",
        "    else: return torch.tensor([0], dtype=torch.long, device=device)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hbhEwlP8xH3"
      },
      "source": [
        "#### Training FNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzMBVoCE85Ay"
      },
      "source": [
        "Hyperparameters: <hr>\n",
        "\n",
        "VOCAB_SIZE = len(review_dict) i.e. 111692 <br>\n",
        "input_dim = VOCAB_SIZE = 111692 <br>\n",
        "hidden_dim = 500 <br>\n",
        "output_dim = 2 <br>\n",
        "num_epochs = 10 <br>\n",
        "learning_rate=0.01 <br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aZ11U0G8wOW"
      },
      "source": [
        "# model\n",
        "ff_nn_bow_model = FeedforwardNN(input_dim, hidden_dim, output_dim).to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(ff_nn_bow_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQv-RPKyB3u1"
      },
      "source": [
        "#writing the loss value in a file\n",
        "ffnn_loss_file_name = 'ffnn_loss.csv'\n",
        "f = open(ffnn_loss_file_name,'w')\n",
        "f.write('iter,loss')\n",
        "f.write('\\n'    )\n",
        "losses=[]\n",
        "iter=0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhAFWrFhDTXa"
      },
      "source": [
        "#starting training\n",
        "a=0\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss=0\n",
        "  for index, row in X_train.iterrows():\n",
        "    #Clearing the accumulated gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Make the bag of words vector for stemmed tokens \n",
        "    bow_vec = make_bow_vector(review_dict, row[\"tokenized_text\"])\n",
        "      \n",
        "    #Forward pass to get output\n",
        "    probs = ff_nn_bow_model(bow_vec)\n",
        "\n",
        "    #Getting the target label\n",
        "    target = make_target(Y_train[\"sentiment\"][index])\n",
        "\n",
        "    #Calculate loss\n",
        "    loss = loss_function(probs,target)\n",
        "    \n",
        "    #Accumulating the loss over time\n",
        "    train_loss += loss.item()\n",
        "    \n",
        "    #Getting gradients wrt paramters:-\n",
        "    loss.backward()\n",
        "\n",
        "    #Updating Paramters\n",
        "    optimizer.step()\n",
        "\n",
        "    if a%1000 == 0: print(epoch)\n",
        "\n",
        "    if (a+1)%10000 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{a+1}/{input_dim}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    a+=1\n",
        "\n",
        "  f.write(str(epoch+1) + \",\" + str(train_loss/len(X_train))  )\n",
        "  f.write(\"\\n\")\n",
        "  train_loss=0\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hezJjK9mFkXp"
      },
      "source": [
        "bow_ff_nn_predictions = []\n",
        "original_lables_ff_bow = []\n",
        "with torch.no_grad():\n",
        "    for index, row in X_test.iterrows():\n",
        "        bow_vec = make_bow_vector(review_dict, row)\n",
        "        probs = ff_nn_bow_model(bow_vec)\n",
        "        bow_ff_nn_predictions.append(torch.argmax(probs, dim=1).cpu().numpy()[0])\n",
        "        original_lables_ff_bow.append(make_target(Y_test[\"sentiment\"][index]).cpu().numpy()[0])\n",
        "print(classification_report(original_lables_ff_bow,bow_ff_nn_predictions))\n",
        "ffnn_loss_df = pd.read_csv(ffnn_loss_file_name)\n",
        "print(len(ffnn_loss_df))\n",
        "print(ffnn_loss_df.columns)\n",
        "ffnn_plt_500_padding_100_epochs = ffnn_loss_df[' loss'].plot()\n",
        "fig = ffnn_plt_500_padding_100_epochs.get_figure()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}